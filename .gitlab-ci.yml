stages:
  - build
  - test
  - format
  - build-docker
  - deploy

variables:
  DEV_BRANCH: "master"
  STG_BRANCH: "staging"
  PROD_BRANCH: "production"
  NODE_IMAGE: "node:18"
  PYTHON_IMAGE: "python:3.9.1-buster"


build info:
  # Always runs: allows pipeline execution to happen even if no other tasks run.
  stage: build
  image: alpine:latest
  tags:
    - docker
  rules:
    - if: $CI_PIPELINE_SOURCE != "push"
  script:
    - echo "This task give the CI/CD pipeline something to (almost always) run."
    - echo "  CI_PIPELINE_SOURCE  = $CI_PIPELINE_SOURCE"
    - echo "  CI_MERGE_REQUEST_ID = $CI_MERGE_REQUEST_ID"
    - echo "  CI_COMMIT_BRANCH    = $CI_COMMIT_BRANCH"


frontend build:
  stage: build
  needs: []
  image: $NODE_IMAGE
  tags:
    - docker
  rules:
    # ensure frontend builds if any frontend files have changed in the MR
    - if: '$CI_MERGE_REQUEST_ID != null'
      changes:
        - client/**/*
      when: always
    # always run if deploying
    - if: '$CI_COMMIT_BRANCH == $DEV_BRANCH || $CI_COMMIT_BRANCH == $STG_BRANCH'
      when: always
    # Always build/test for schedule / manual "Run Pipeline" via web
    - if: $CI_PIPELINE_SOURCE == "schedule"
    - if: $CI_PIPELINE_SOURCE == "web"
  before_script:
    - cd client
    - npm i --global npm@7
    - npm ci
  script:
    - GENERATE_SOURCEMAP=false npm run build
  after_script:
    - cd client/build && tar -czvf ../../frontend.tar.gz .
  artifacts:
    expire_in: 1 week
    paths:
      - frontend.tar.gz

update aws:
  stage: build
  needs: []
  image: ubuntu:latest
  tags:
    - docker
  rules:
    - if: '$CI_MERGE_REQUEST_ID != null || $CI_COMMIT_BRANCH == $DEV_BRANCH'
      changes:
        - aws/**/*
      when: always
    # Always build/test for schedule / manual "Run Pipeline" via web
    - if: $CI_PIPELINE_SOURCE == "schedule"
    - if: $CI_PIPELINE_SOURCE == "web"
  before_script:
    - apt update
    - apt install -y unzip zip curl
    - curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
    - unzip awscliv2.zip
    - ./aws/install
    - aws configure set aws_access_key_id $AWS_ACCESS_KEY_ID
    - aws configure set aws_secret_access_key $AWS_SECRET_ACCESS_KEY
    - aws configure set default.region us-west-2
  script:
    - cd aws
    # Deploy the CloudFormation stack
    - aws cloudformation deploy --template-file aws-cfn/fluentbit-user-iam.yml --stack-name logs-cradle-staging --region us-east-1 --capabilities CAPABILITY_NAMED_IAM --parameter-overrides LogGroupPrefix=cradle-staging --no-fail-on-empty-changeset
    - aws cloudformation deploy --template-file aws-cfn/gitlab-ci-iam.yml --stack-name cradle-gitlab-ci --region us-east-1 --capabilities CAPABILITY_NAMED_IAM --no-fail-on-empty-changeset --no-fail-on-empty-changeset

    # Update the Lambda function code
    - zip cpuAlarmLambda.zip aws-lambda/cpuAlarmLambda.py 
    - aws lambda update-function-code --function-name CPUAlarms --zip-file fileb://cpuAlarmLambda.zip --region us-west-2


backend unit tests:
  stage: test
  needs: []
  image: $PYTHON_IMAGE
  tags:
    - docker
  rules:
    - if: '$CI_MERGE_REQUEST_ID != null || $CI_COMMIT_BRANCH == $DEV_BRANCH'
      changes:
        - server/**/*
      when: always
    # Always build/test for schedule / manual "Run Pipeline" via web
    - if: $CI_PIPELINE_SOURCE == "schedule"
    - if: $CI_PIPELINE_SOURCE == "web"
  before_script:
    - cd server
    - pip install --upgrade pip
    - pip install -r requirements.txt
  script:
    - python -m pytest --junitxml=report.xml tests
  artifacts:
    when: always
    expire_in: 1 week
    reports:
      junit: server/report.xml

backend system tests:
  stage: test
  needs: []
  image: $PYTHON_IMAGE
  tags:
    - docker
  rules:
    - if: '$CI_MERGE_REQUEST_ID != null || $CI_COMMIT_BRANCH == $DEV_BRANCH'
      changes:
        - server/**/*
      when: always
    # Always build/test for schedule / manual "Run Pipeline" via web
    - if: $CI_PIPELINE_SOURCE == "schedule"
    - if: $CI_PIPELINE_SOURCE == "web"
  variables:
    DB_USERNAME: "root"
    DB_PASSWORD: "ci-password"
    DB_HOSTNAME: "mysql"
    DB_PORT: "3306"
    DB_NAME: "cradle"
    PORT: "5000"
    MYSQL_DATABASE: "cradle"
    MYSQL_ROOT_PASSWORD: "ci-password"
    JWT_SECRET_KEY: "testkey"
    LIMITER_DISABLED: "True"
    EMULATOR_PHONE_NUMBER: "+1-123-456-7890"
  services:
    - mysql:5.7
  before_script:
    - apt-get update -y
    - apt-get install default-mysql-client -y
    - cd server
    - pip install --upgrade pip
    - pip install -r requirements.txt
    - python3 app.py &
    - python3 db.py rebuild --no-docker
    - python3 manage.py seed_test_data
  script:
    - python -m pytest --junitxml=report.xml systemTests
  artifacts:
    when: always
    expire_in: 1 week
    reports:
      junit: server/report.xml

frontend unit tests:
  stage: test
  needs: []
  image: $NODE_IMAGE
  tags:
    - docker
  rules:
    - if: '$CI_MERGE_REQUEST_ID != null || $CI_COMMIT_BRANCH == $DEV_BRANCH'
      changes:
        - client/**/*
      when: always
    # Always build/test for schedule / manual "Run Pipeline" via web
    - if: $CI_PIPELINE_SOURCE == "schedule"
    - if: $CI_PIPELINE_SOURCE == "web"
  before_script:
    - cd client 
    - npm i --global npm@7
    - npm ci
  script:
    - npm run test --args a

frontend integration tests:
  stage: test
  needs: []
  image: $NODE_IMAGE
  variables:
    CI: "true"
    DB_USERNAME: "root"
    DB_PASSWORD: "ci-password"
    DB_HOSTNAME: "mysql"
    DB_PORT: "3306"
    DB_NAME: "cradle"
    MYSQL_DATABASE: "cradle"
    MYSQL_ROOT_PASSWORD: "ci-password"
    JWT_SECRET_KEY: "testkey"  
  services:
    - mysql:5.7
  tags:
    - docker
  rules:
    - if: '$CI_MERGE_REQUEST_ID != null || $CI_COMMIT_BRANCH == $DEV_BRANCH'
      changes:
        - client/**/*
      when: always
    # Always build/test for schedule / manual "Run Pipeline" via web
    - if: $CI_PIPELINE_SOURCE == "schedule"
    - if: $CI_PIPELINE_SOURCE == "web"
  before_script:
    - export PORT="5000"
    - apt-get update -y
    - apt-get install default-mysql-client python3-pip python3-venv -y
    - apt-get install libgtk2.0-0 libgtk-3-0 libgbm-dev libnotify-dev libgconf-2-4 libnss3 libxss1 libasound2 libxtst6 xauth xvfb -y #cypress dependencies
    - cd server
    - python3 -m venv /venv                         # Python 3.11+ does not allow pip to install into global context; use a virtual environment instead.
    - export PATH=$PATH:/venv/bin/                  # Add virtual environment to path so app's call to `flask` succeed
    - /venv/bin/pip3 install --upgrade pip
    - /venv/bin/pip3 install -r requirements.txt
    - /venv/bin/python3 app.py &
    - /venv/bin/python3 db.py rebuild --no-docker
    - /venv/bin/python3 manage.py seed_test_data
    - cd ../client
    - npm i --global npm@7
    - npm ci
    - export PORT="3000" #overwrite port for npm
  script:
    - npm run start &
    - npx wait-on http://localhost:3000
    - npm run e2e
  artifacts:
    when: on_failure
    paths:
       - client/cypress/screenshots/**/*.png
       - client/cypress/videos/**/*.mp4
    expire_in: 1 week

frontend lint:
  stage: format
  needs: []
  image: $NODE_IMAGE
  tags:
    - docker
  rules:
    - if: '$CI_MERGE_REQUEST_ID != null || $CI_COMMIT_BRANCH == $DEV_BRANCH'
      changes:
        - client/**/*
      when: always
    # Always build/test for schedule / manual "Run Pipeline" via web
    - if: $CI_PIPELINE_SOURCE == "schedule"
    - if: $CI_PIPELINE_SOURCE == "web"
  before_script:
    - cd client
    - npm i --global npm@7
    - npm ci
  script:
    - ./node_modules/.bin/eslint "src/**/*.{ts,tsx}"

frontend format:
  stage: format
  needs: []
  image: $NODE_IMAGE
  tags:
    - docker
  rules:
    - if: '$CI_MERGE_REQUEST_ID != null || $CI_COMMIT_BRANCH == $DEV_BRANCH'
      changes:
        - client/**/*
      when: always
    # Always build/test for schedule / manual "Run Pipeline" via web
    - if: $CI_PIPELINE_SOURCE == "schedule"
    - if: $CI_PIPELINE_SOURCE == "web"
  before_script:
    # Prettier version here should match version in package.json
    - npm i --global npm@7
    - npm install prettier@2.7.1 --global
  script:
    - prettier --check "client/src/**/*.{ts,tsx}"

backend format:
  stage: format
  needs: []
  image: $PYTHON_IMAGE
  tags:
    - docker
  rules:
    - if: '$CI_MERGE_REQUEST_ID != null || $CI_COMMIT_BRANCH == $DEV_BRANCH'
      changes:
        - server/**/*
      when: always
    # Always build/test for schedule / manual "Run Pipeline" via web
    - if: $CI_PIPELINE_SOURCE == "schedule"
    - if: $CI_PIPELINE_SOURCE == "web"
  before_script:
    - cd server
    - pip install --upgrade pip
    # Ensure we get the same version of Black used by the project
    - pip install -r requirements.txt
  script:
    - black --check --exclude 'server/migrations/.*' .
    

.deploy-script: &export_image_tag
  # Set IMAGE_TAG to encode the date and SHA of the most recent commit.
  - export IMAGE_TAG=v$(git show -s --format=%cs $CI_COMMIT_SHA).`git rev-parse --short=8 $CI_COMMIT_SHA`
  # Display some useful info for understanding / debugging the pipeline
  - echo "Docker hub user ='$HUB_USER',     version='$IMAGE_TAG'"
  - echo "Full tag (backend) is               = $HUB_USER/$HUB_REPO_BACKEND:$IMAGE_TAG"
  - echo "Full tag (rev-proxy & frontend) is  = $HUB_USER/$HUB_REPO_FRONTEND:$IMAGE_TAG"
  - docker images


build-docker publish-docker-images:
  stage: build-docker
  tags:
    # Run on CI/CD server so it does not interfere with containers in active use on dev server.
    - deploy-dockerhub-shell
  rules:
    - if: "$CI_COMMIT_BRANCH == $DEV_BRANCH"
    - if: $CI_PIPELINE_SOURCE == "web"
  script:
    # Required environment variables defined by GitLab's settings:
    #   HUB_USER:           Docker Hub user
    #   HUB_TOKEN:          Docker Hub token (likely GitLab will "Mask")
    #   HUB_REPO_BACKEND:   Docker Hub project name for backend
    #   HUB_REPO_FRONTEND:  Docker Hub project name for frontend / caddy

    # Build images (tagged by docker-composition*.yml using IMAGE_TAG)
    - *export_image_tag
    - docker compose -f docker-compose.yml -f docker-compose.deploy.yml build
    
    # Push images to Docker Hub 
    - docker images
    - docker login -u $HUB_USER -p $HUB_TOKEN
    - docker push $HUB_USER/$HUB_REPO_BACKEND:$IMAGE_TAG
    - docker push $HUB_USER/$HUB_REPO_FRONTEND:$IMAGE_TAG
    - docker logout

    # Cleanup the image and any tags of that image
    # Run on the CI/CD server, so it can force delete these images because it does not run any of them as containers
    - docker images -a | grep -e "$HUB_REPO_BACKEND" -e "$HUB_REPO_FRONTEND" | awk '{print $3}' | xargs docker rmi --force
    - docker images


.deploy-script: &deploy-from-dockerhub
  - *export_image_tag
  - cp /var/cradle/.env ./.env
  - docker compose -f docker-compose.yml -f docker-compose.deploy.yml pull
  - export ENV=$CI_ENVIRONMENT_NAME
  - docker compose -f docker-compose.yml -f docker-compose.deploy.yml up -d
  - docker image prune -f      # remove unused images since we just downloaded new ones
  - bash -c 'sleep 15'
  - docker exec cradle_flask flask db upgrade
  - docker images
  - docker ps -a
  - docker volume ls
  - docker restart cradle_fluentbit #fluentbit needs a restart after every changes made

.deploy-script: &retag-and-upload-dockerhub
  # Required environment variables passed into this function:
  #   BRANCH_TAG:         Determined by which branch we are building off: "dev", "staging", "prod"
  - *export_image_tag

  # Download images (docker skips if already be present)
  - echo "Trying to tag images of version '$IMAGE_TAG' with new tag '$BRANCH_TAG'"
  - | 
    echo "If you get 'Error response from daemon - manifest for ... not found - manifest unknown - manifest unknown'"
    echo "   it likely means the pipeline did not build and deploy a docker image for this commit."
    echo "   Was there a MR to this branch that did not get build for use on Dev server?"
  - echo "Downloading image = $HUB_USER/$HUB_REPO_BACKEND, tag = $IMAGE_TAG'..."
  - docker pull $HUB_USER/$HUB_REPO_BACKEND:$IMAGE_TAG
  - docker pull $HUB_USER/$HUB_REPO_FRONTEND:$IMAGE_TAG

  # Retag
  - docker tag $HUB_USER/$HUB_REPO_BACKEND:$IMAGE_TAG   $HUB_USER/$HUB_REPO_BACKEND:$BRANCH_TAG
  - docker tag $HUB_USER/$HUB_REPO_FRONTEND:$IMAGE_TAG  $HUB_USER/$HUB_REPO_FRONTEND:$BRANCH_TAG

  # Upload tags
  - docker images
  - docker login -u $HUB_USER -p $HUB_TOKEN
  - docker push $HUB_USER/$HUB_REPO_BACKEND:$BRANCH_TAG
  - docker push $HUB_USER/$HUB_REPO_FRONTEND:$BRANCH_TAG
  - docker logout

  # Cleanup (if in use as a container this will fail, so we tolerate failures)
  - docker rmi $HUB_USER/$HUB_REPO_BACKEND:$BRANCH_TAG || true
  - docker rmi $HUB_USER/$HUB_REPO_FRONTEND:$BRANCH_TAG || true
  - docker rmi $HUB_USER/$HUB_REPO_BACKEND:$IMAGE_TAG || true
  - docker rmi $HUB_USER/$HUB_REPO_FRONTEND:$IMAGE_TAG || true
  - docker images

  
deploy development:
  stage: deploy
  environment:
    name: development
    url: https://cradle-dev.cmpt.sfu.ca
  tags:
    - deploy-development
  variables:
    BRANCH_TAG: "dev"
  rules:
    - if: "$CI_COMMIT_BRANCH == $DEV_BRANCH"
    - if: $CI_PIPELINE_SOURCE == "web"
      when: manual
  script:
    # After images are built, deploy to dev-server & tag with "dev"
    - *deploy-from-dockerhub
    - *retag-and-upload-dockerhub

deploy staging:
  stage: deploy
  environment:
    name: staging
    url: https://cradle-stg.cmpt.sfu.ca
  tags:
    - deploy-staging
  variables:
    BRANCH_TAG: "staging"
  rules:
    - if: "$CI_COMMIT_BRANCH == $STG_BRANCH"
    - if: $CI_PIPELINE_SOURCE == "web"
      when: manual
  script:
    - *deploy-from-dockerhub
    - *retag-and-upload-dockerhub

deploy production:
  stage: deploy
  tags:
    - deploy-dockerhub-shell
  variables:
    BRANCH_TAG: "prod"
  rules:
    - if: "$CI_COMMIT_BRANCH == $PROD_BRANCH"
    - if: $CI_PIPELINE_SOURCE == "web"
      when: manual
  script:
    - *retag-and-upload-dockerhub
    # Production server's admin must manually log into the server and run the /root/update.sh script
